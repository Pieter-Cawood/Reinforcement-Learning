# Cliffwalking

Use the CliffWalking domain from OpenAI gym
â€¢ See Example 6.6, pg 132 in Sutton and Barto [2018]
â€¢ Modify the TD(ğœ†) algorithm presented to implement SARSA(ğœ†)
â€¢ The only difference here is that there is an eligibility trace for each state-action
pair!
â€¢ See the first edition of Sutton and Barto for more info
â€¢ Use ğœ€-greedy policies with ğœ€ = 0.1 and a learning rate of ğ›¼ = 0.5
â€¢ Run SARSA(ğœ†) on the domain for ğœ† = {0, 0.3, 0.5, 0.7, 0.9} for 500 episodes
â€¢ Record the current estimate of the Q-value function after each episode

